# Databricks Intro 

## Sesión 1: Visión General de Databricks y Arquitectura de Clusters 

*Objetivo*: Presentar la plataforma, sus componentes clave y explicar los tipos básicos de clusters (2h). 

• Introducción a Databricks: historia, arquitectura y principales casos de uso. 

• Tipos de clusters en Databricks: Ventajas, desventajas y cuándo usar cada uno. Exploración del Workspace: notebooks, jobs y gestión de librerías. 

• Demostración práctica: creación y configuración de un cluster básico y navegación 

## Sesión 2: Fundamentos de Apache Spark y Primeros Pasos en Notebooks 

*Objetivo*: Introducir Apache Spark en Databricks, trabajar con DataFrames y SQL (2h). 

• Introducción a Apache Spark: RDDs, DataFrames, Datasets y Spark SQL. 

• Uso de notebooks en Databricks para procesamiento de datos: sintaxis, celdas y ejecución. 

• Ejercicio práctico: carga y transformación de datos en un DataFrame y ejecución de consultas SQL. 

• Demostración de visualización de datos y creación de dashboards simples. 

• Sesión de preguntas y cierre. 

## Sesión 3: Análisis Exploratorio y Introducción a Unity Catalog 

*Objetivo*: Profundizar en el análisis de datos y presentar de forma introductoria el concepto de Unity Catalog para la gobernanza de datos (2h). 

• Breve repaso de sesiones previas y presentación de objetivos. 

• Técnicas de análisis exploratorio de datos (EDA) usando Spark y SQL en Databricks. 

• Introducción a Unity Catalog: qué es, por qué es importante y sus componentes básicos (catálogos, esquemas, tablas). 

• Demostración práctica: exploración de datos y configuración básica de Unity Catalog en un entorno de prueba. 

• Ejercicio práctico: consulta y visualización de metadatos a través de Unity Catalog